{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "db5208429cfa4917"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.539177Z",
     "start_time": "2024-11-25T12:26:06.727479Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Huggingface\n",
    "import huggingface_hub\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Unsloth\n",
    "from unsloth import FastLanguageModel, is_bf16_supported"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "57abf30d627ee09e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.544513Z",
     "start_time": "2024-11-25T12:26:11.540573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    # Model\n",
    "    model_id: str = \"PathFinderKR/KHU-Llama-3.2-1B-Instruct-SFT\"\n",
    "    model_type: str = \"instruct\"\n",
    "    \n",
    "    # Inference\n",
    "    max_new_tokens: int = 2048\n",
    "    do_sample: bool = True\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    repetition_penalty: float = 1.1\n",
    "    dtype: torch.dtype = torch.bfloat16 if is_bf16_supported() else torch.float16\n",
    "    load_in_4bit: bool = True\n",
    "    \n",
    "    # Device\n",
    "    device: torch.device = None\n",
    "    \n",
    "    # Seed\n",
    "    seed: int = 42"
   ],
   "id": "1e40d5f72df04655",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reproducibility",
   "id": "f46db0f1bc936647"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.556034Z",
     "start_time": "2024-11-25T12:26:11.545793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "set_seed(CONFIG.seed)"
   ],
   "id": "8af068b3748857a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "fbfd69b58b4f084"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.563668Z",
     "start_time": "2024-11-25T12:26:11.557314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"> Running on MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "28da07e74fabc081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## HuggingFace",
   "id": "696491e2e0ee1f7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:26:11.850318Z",
     "start_time": "2024-11-25T12:26:11.565107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "huggingface_hub.login(\n",
    "    token=os.getenv(\"HUGGINGFACE_TOKEN\"),\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "id": "aa612bd605c0a3d6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "af7858b04f878907"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:30:02.747936Z",
     "start_time": "2024-11-25T12:26:11.851462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=CONFIG.model_id,\n",
    "    max_seq_length=CONFIG.max_new_tokens,\n",
    "    dtype=CONFIG.dtype,\n",
    "    load_in_4bit=CONFIG.load_in_4bit\n",
    ")"
   ],
   "id": "5db78c3baf173b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.8: Fast Llama patching. Transformers = 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4080 SUPER. Max memory: 15.992 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1. CUDA = 8.9. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8368b0b92f4e48e8959c2a63dc7edc52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99715264123d435f9946fcb19334b177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "923f5b54d7164d0894e8227fbf5032e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da18805aeb004add9dfecb190125caeb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90ff4fd31b8543de8ffd8062c6ed3ab1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:30:02.751653Z",
     "start_time": "2024-11-25T12:30:02.749224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "text_streamer = TextStreamer(tokenizer)"
   ],
   "id": "d0685ccc663499a9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "855210326205f00c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:30:02.761302Z",
     "start_time": "2024-11-25T12:30:02.752738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llama_3_instruct_prompt = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{}\"\"\"\n",
    "\n",
    "# Generate base model\n",
    "def generate_text(prompt):\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    inputs = tokenizer(\n",
    "    [\n",
    "        prompt\n",
    "    ], return_tensors = \"pt\").to(CONFIG.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=CONFIG.max_new_tokens,\n",
    "        do_sample=CONFIG.do_sample,\n",
    "        temperature=CONFIG.temperature,\n",
    "        top_p=CONFIG.top_p,\n",
    "        repetition_penalty=CONFIG.repetition_penalty,\n",
    "        use_cache=True,\n",
    "        streamer=TextStreamer(tokenizer)\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=False)\n",
    "\n",
    "# Generate instruction model\n",
    "def generate_response(system, user):\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    inputs = tokenizer(\n",
    "    [\n",
    "        llama_3_instruct_prompt.format(\n",
    "            system,\n",
    "            user,\n",
    "            \"\"\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(CONFIG.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=CONFIG.max_new_tokens,\n",
    "        do_sample=CONFIG.do_sample,\n",
    "        temperature=CONFIG.temperature,\n",
    "        top_p=CONFIG.top_p,\n",
    "        repetition_penalty=CONFIG.repetition_penalty,\n",
    "        use_cache=True,\n",
    "        streamer=TextStreamer(tokenizer)\n",
    "    )\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=False)"
   ],
   "id": "acd28280dfdca5d6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T12:39:06.932191Z",
     "start_time": "2024-11-25T12:38:57.343352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if CONFIG.model_type == \"base\":\n",
    "    sample_text = \"Capital of France:\"\n",
    "    sample_response = generate_text(sample_text)\n",
    "    print(sample_response)\n",
    "    print(tokenizer.tokenize(sample_response[0]))\n",
    "elif CONFIG.model_type == \"instruct\":\n",
    "    sample_system = \"You are a helpful assistant.\"\n",
    "    sample_user = \"How are final exams structured in June?\"\n",
    "    sample_response = generate_response(sample_system, sample_user)\n",
    "    print(sample_response)\n",
    "    print(tokenizer.tokenize(sample_response[0]))"
   ],
   "id": "bcb8683e4df9bdfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How are final exams structured in June?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In the month of June, students typically take several final exams as part of their academic progression. Hereâ€™s how they are structured and what to expect:\\n\\n1. **Final Exams Structure**: \\n   - Students usually take multiple courses, each with its own set of subjects or credits.\\n   - The course structure may vary by institution; some might have a single subject while others offer multiple subjects.\\n   - For example, a student taking 'Physics 101' might also encounter 'Physics 102', which could be worth additional credit towards their degree.\\n\\n2. **Timing of Final Exams**:\n",
      "   - These exams often occur in the last semester of the year, specifically between December 15th and January 20th.\\n   - This timing allows for proper grading and feedback before the end of the term.\\n\\n3. **Types of Final Exams**:\n",
      "   - **Multiple Subject Examination**: Many institutions require students to pass multiple subject examinations at the end of their studies. \\n   - A typical setup would involve a short exam that covers core knowledge areas specific to each subject.\\n   - Examples include a written examination covering basic physics concepts followed by practical tests related to those topics.\\n\\n4. **Grade Distribution**:\n",
      "   - After conducting these exams, students receive grades on a scale (e.g., A, B, C) based on their performance. \\n   - Grades can reflect both theoretical understanding and practical application, allowing for a holistic assessment of their abilities.\\n\\n5. **Credit Recognition**:\n",
      "   - In many cases, successful completion of multiple exams leads to recognition of additional credits toward graduation. \\n   - Students may earn up to 6 credits for passing individual exams, depending on the institution's policies.\\n\\nOverall, the structure of final exams in June ensures that students are adequately prepared for their future academic endeavors by providing comprehensive assessments that reflect their learning capabilities.<|eot_id|>\n",
      "[\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow are final exams structured in June?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nIn the month of June, students typically take several final exams as part of their academic progression. Hereâ€™s how they are structured and what to expect:\\\\n\\\\n1. **Final Exams Structure**: \\\\n   - Students usually take multiple courses, each with its own set of subjects or credits.\\\\n   - The course structure may vary by institution; some might have a single subject while others offer multiple subjects.\\\\n   - For example, a student taking 'Physics 101' might also encounter 'Physics 102', which could be worth additional credit towards their degree.\\\\n\\\\n2. **Timing of Final Exams**:\\n   - These exams often occur in the last semester of the year, specifically between December 15th and January 20th.\\\\n   - This timing allows for proper grading and feedback before the end of the term.\\\\n\\\\n3. **Types of Final Exams**:\\n   - **Multiple Subject Examination**: Many institutions require students to pass multiple subject examinations at the end of their studies. \\\\n   - A typical setup would involve a short exam that covers core knowledge areas specific to each subject.\\\\n   - Examples include a written examination covering basic physics concepts followed by practical tests related to those topics.\\\\n\\\\n4. **Grade Distribution**:\\n   - After conducting these exams, students receive grades on a scale (e.g., A, B, C) based on their performance. \\\\n   - Grades can reflect both theoretical understanding and practical application, allowing for a holistic assessment of their abilities.\\\\n\\\\n5. **Credit Recognition**:\\n   - In many cases, successful completion of multiple exams leads to recognition of additional credits toward graduation. \\\\n   - Students may earn up to 6 credits for passing individual exams, depending on the institution's policies.\\\\n\\\\nOverall, the structure of final exams in June ensures that students are adequately prepared for their future academic endeavors by providing comprehensive assessments that reflect their learning capabilities.<|eot_id|>\"]\n",
      "['<|begin_of_text|>', '<|start_header_id|>', 'system', '<|end_header_id|>', 'ÄŠÄŠ', 'You', 'Ä are', 'Ä a', 'Ä helpful', 'Ä assistant', '.', '<|eot_id|>', '<|start_header_id|>', 'user', '<|end_header_id|>', 'ÄŠÄŠ', 'How', 'Ä are', 'Ä final', 'Ä exams', 'Ä structured', 'Ä in', 'Ä June', '?', '<|eot_id|>', '<|start_header_id|>', 'assistant', '<|end_header_id|>', 'ÄŠÄŠ', 'In', 'Ä the', 'Ä month', 'Ä of', 'Ä June', ',', 'Ä students', 'Ä typically', 'Ä take', 'Ä several', 'Ä final', 'Ä exams', 'Ä as', 'Ä part', 'Ä of', 'Ä their', 'Ä academic', 'Ä progression', '.', 'Ä Here', 'Ã¢Ä¢Ä»s', 'Ä how', 'Ä they', 'Ä are', 'Ä structured', 'Ä and', 'Ä what', 'Ä to', 'Ä expect', ':\\\\', 'n', '\\\\n', '1', '.', 'Ä **', 'Final', 'Ä Ex', 'ams', 'Ä Structure', '**:', 'Ä \\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä Students', 'Ä usually', 'Ä take', 'Ä multiple', 'Ä courses', ',', 'Ä each', 'Ä with', 'Ä its', 'Ä own', 'Ä set', 'Ä of', 'Ä subjects', 'Ä or', 'Ä credits', '.\\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä The', 'Ä course', 'Ä structure', 'Ä may', 'Ä vary', 'Ä by', 'Ä institution', ';', 'Ä some', 'Ä might', 'Ä have', 'Ä a', 'Ä single', 'Ä subject', 'Ä while', 'Ä others', 'Ä offer', 'Ä multiple', 'Ä subjects', '.\\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä For', 'Ä example', ',', 'Ä a', 'Ä student', 'Ä taking', \"Ä '\", 'Physics', 'Ä ', '101', \"'\", 'Ä might', 'Ä also', 'Ä encounter', \"Ä '\", 'Physics', 'Ä ', '102', \"',\", 'Ä which', 'Ä could', 'Ä be', 'Ä worth', 'Ä additional', 'Ä credit', 'Ä towards', 'Ä their', 'Ä degree', '.\\\\', 'n', '\\\\n', '2', '.', 'Ä **', 'Timing', 'Ä of', 'Ä Final', 'Ä Ex', 'ams', '**', ':ÄŠ', 'Ä Ä ', 'Ä -', 'Ä These', 'Ä exams', 'Ä often', 'Ä occur', 'Ä in', 'Ä the', 'Ä last', 'Ä semester', 'Ä of', 'Ä the', 'Ä year', ',', 'Ä specifically', 'Ä between', 'Ä December', 'Ä ', '15', 'th', 'Ä and', 'Ä January', 'Ä ', '20', 'th', '.\\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä This', 'Ä timing', 'Ä allows', 'Ä for', 'Ä proper', 'Ä grading', 'Ä and', 'Ä feedback', 'Ä before', 'Ä the', 'Ä end', 'Ä of', 'Ä the', 'Ä term', '.\\\\', 'n', '\\\\n', '3', '.', 'Ä **', 'Types', 'Ä of', 'Ä Final', 'Ä Ex', 'ams', '**', ':ÄŠ', 'Ä Ä ', 'Ä -', 'Ä **', 'Multiple', 'Ä Subject', 'Ä Examination', '**:', 'Ä Many', 'Ä institutions', 'Ä require', 'Ä students', 'Ä to', 'Ä pass', 'Ä multiple', 'Ä subject', 'Ä examinations', 'Ä at', 'Ä the', 'Ä end', 'Ä of', 'Ä their', 'Ä studies', '.', 'Ä \\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä A', 'Ä typical', 'Ä setup', 'Ä would', 'Ä involve', 'Ä a', 'Ä short', 'Ä exam', 'Ä that', 'Ä covers', 'Ä core', 'Ä knowledge', 'Ä areas', 'Ä specific', 'Ä to', 'Ä each', 'Ä subject', '.\\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä Examples', 'Ä include', 'Ä a', 'Ä written', 'Ä examination', 'Ä covering', 'Ä basic', 'Ä physics', 'Ä concepts', 'Ä followed', 'Ä by', 'Ä practical', 'Ä tests', 'Ä related', 'Ä to', 'Ä those', 'Ä topics', '.\\\\', 'n', '\\\\n', '4', '.', 'Ä **', 'Grade', 'Ä Distribution', '**', ':ÄŠ', 'Ä Ä ', 'Ä -', 'Ä After', 'Ä conducting', 'Ä these', 'Ä exams', ',', 'Ä students', 'Ä receive', 'Ä grades', 'Ä on', 'Ä a', 'Ä scale', 'Ä (', 'e', '.g', '.,', 'Ä A', ',', 'Ä B', ',', 'Ä C', ')', 'Ä based', 'Ä on', 'Ä their', 'Ä performance', '.', 'Ä \\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä Grades', 'Ä can', 'Ä reflect', 'Ä both', 'Ä theoretical', 'Ä understanding', 'Ä and', 'Ä practical', 'Ä application', ',', 'Ä allowing', 'Ä for', 'Ä a', 'Ä holistic', 'Ä assessment', 'Ä of', 'Ä their', 'Ä abilities', '.\\\\', 'n', '\\\\n', '5', '.', 'Ä **', 'Credit', 'Ä Recognition', '**', ':ÄŠ', 'Ä Ä ', 'Ä -', 'Ä In', 'Ä many', 'Ä cases', ',', 'Ä successful', 'Ä completion', 'Ä of', 'Ä multiple', 'Ä exams', 'Ä leads', 'Ä to', 'Ä recognition', 'Ä of', 'Ä additional', 'Ä credits', 'Ä toward', 'Ä graduation', '.', 'Ä \\\\', 'n', 'Ä Ä ', 'Ä -', 'Ä Students', 'Ä may', 'Ä earn', 'Ä up', 'Ä to', 'Ä ', '6', 'Ä credits', 'Ä for', 'Ä passing', 'Ä individual', 'Ä exams', ',', 'Ä depending', 'Ä on', 'Ä the', 'Ä institution', \"'s\", 'Ä policies', '.\\\\', 'n', '\\\\n', 'Overall', ',', 'Ä the', 'Ä structure', 'Ä of', 'Ä final', 'Ä exams', 'Ä in', 'Ä June', 'Ä ensures', 'Ä that', 'Ä students', 'Ä are', 'Ä adequately', 'Ä prepared', 'Ä for', 'Ä their', 'Ä future', 'Ä academic', 'Ä endeavors', 'Ä by', 'Ä providing', 'Ä comprehensive', 'Ä assessments', 'Ä that', 'Ä reflect', 'Ä their', 'Ä learning', 'Ä capabilities', '.', '<|eot_id|>']\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
