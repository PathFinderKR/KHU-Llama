{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "956f0004f133f26d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:34.498595Z",
     "start_time": "2024-11-03T07:55:29.966396Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Huggingface\n",
    "import huggingface_hub\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters",
   "id": "9d5e4c6251952a7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:34.503042Z",
     "start_time": "2024-11-03T07:55:34.499787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    debug: bool = False\n",
    "    \n",
    "    # Model\n",
    "    username: str = \"PathFinderKR\"\n",
    "    model_name: str = \"Llama-3.2-KO-1B-Instruct\"\n",
    "    model_id: str = f\"{username}/{model_name}\"\n",
    "    \n",
    "    # Inference\n",
    "    max_new_tokens: int = 128000\n",
    "    do_sample: bool = True\n",
    "    temperature: float = 0.7\n",
    "    top_p: float = 0.9\n",
    "    repetition_penalty: float = 1.1\n",
    "    \n",
    "    # Device\n",
    "    device: torch.device = None\n",
    "    attn_implementation: str = None\n",
    "    torch_dtype: torch.dtype = torch.bfloat16\n",
    "    \n",
    "    # Seed\n",
    "    seed: int = 42"
   ],
   "id": "cba7c4dd0866b7da",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reproducibility",
   "id": "9d3d141b0757ee3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:34.518595Z",
     "start_time": "2024-11-03T07:55:34.503914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"Seed: {seed}\")\n",
    "    \n",
    "set_seed(CONFIG.seed)"
   ],
   "id": "12418e5e977e473c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "7433ffeaf5966a08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:34.711267Z",
     "start_time": "2024-11-03T07:55:34.519504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"> Running on MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "2552371f947f3c16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:34.715521Z",
     "start_time": "2024-11-03T07:55:34.712870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_attn_implementation(device):\n",
    "    if device == \"cuda\":\n",
    "        if torch.cuda.get_device_capability()[0] >= 8: # Ampere, Ada, or Hopper GPUs\n",
    "            attn_implementation = \"flash_attention_2\"\n",
    "        else:\n",
    "            attn_implementation = \"eager\"\n",
    "    else:\n",
    "        attn_implementation = None\n",
    "    return attn_implementation\n",
    "\n",
    "CONFIG.attn_implementation= configure_attn_implementation(CONFIG.device)"
   ],
   "id": "596541be60a319cb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HuggingFace",
   "id": "10dfcaa91067b591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:34.999826Z",
     "start_time": "2024-11-03T07:55:34.716544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "huggingface_hub.login(\n",
    "    token=os.getenv(\"HUGGINGFACE_TOKEN\"),\n",
    "    add_to_git_credential=True\n",
    ")"
   ],
   "id": "b3747a9f9d1e4d9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/pathfinder/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokenizer",
   "id": "d1a647e909122f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:55:39.442158Z",
     "start_time": "2024-11-03T07:55:35.001013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG.model_id)\n",
    "streamer = TextStreamer(tokenizer)"
   ],
   "id": "d7c5a7bc1e35cbd9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d5c82014222403c8dff2cbb1ff8921b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2e70799ae4846a3b18dfc6e19a65bb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8da938f4c7924168af8fa27b56e51b9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "dac252416e3e18f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:59:17.038321Z",
     "start_time": "2024-11-03T07:55:39.443242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG.model_id,\n",
    "    device_map=CONFIG.device,\n",
    "    attn_implementation=CONFIG.attn_implementation,\n",
    "    torch_dtype=CONFIG.torch_dtype\n",
    ")"
   ],
   "id": "4ee52b941c693d2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/885 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60149148593c4ecea330892b158697ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf8dc1cf764648c49e2e337e11d26137"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/180 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6bad08a001845a6ac4364c09a674623"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "33e59997e1cb20af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:59:17.042562Z",
     "start_time": "2024-11-03T07:59:17.039494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Llama-3-Instruct template\n",
    "def prompt_template(system, user):\n",
    "    return (\n",
    "        \"<|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "        f\"{system}<|eot_id|>\"\n",
    "        \n",
    "        \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "        f\"{user}<|eot_id|>\"\n",
    "        \n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    )\n",
    "\n",
    "def generate_instruct_model(system, user):\n",
    "    prompt = prompt_template(system, user)\n",
    "    \n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(CONFIG.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=CONFIG.max_new_tokens,\n",
    "        do_sample=CONFIG.do_sample,\n",
    "        temperature=CONFIG.temperature,\n",
    "        top_p=CONFIG.top_p,\n",
    "        repetition_penalty=CONFIG.repetition_penalty,\n",
    "        streamer=streamer\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ],
   "id": "5c0a3280160e7e04",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:59:17.050533Z",
     "start_time": "2024-11-03T07:59:17.043604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"다음 지시사항에 대한 응답을 작성해 주세요.\"\n",
    "user_prompt = \"피보나치 수열에 대해 설명해주세요.\""
   ],
   "id": "69d83e34fc3c58fa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T07:59:35.943875Z",
     "start_time": "2024-11-03T07:59:17.051466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = generate_instruct_model(system_prompt, user_prompt)\n",
    "print(response)"
   ],
   "id": "3525186571148062",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "다음 지시사항에 대한 응답을 작성해 주세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "피보나치 수열에 대해 설명해주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "피보나치 수열은 유일한 두 숫자, 0과 1로 시작하는 수열입니다. 이 수열은 다음의 방정식을 사용하여 정렬된 방식으로 계속 확장됩니다:\n",
      "\n",
      "f(n) = f(n-1) + f(n-2)\n",
      "\n",
      "이제 f(4), f(5), f(6)을 구해 봅시다. 첫 번째 피보나치 수열인 0과 1을 계산하고 그 다음 두 항을 계산합니다.\n",
      "\n",
      "f(4) = f(3) + f(2)\n",
      "f(3) = f(2) + f(1)\n",
      "f(2) = f(1) + f(0)\n",
      "\n",
      "따라서 f(4)는 다음과 같습니다:\n",
      "f(4) = (f(3) + f(2)) + f(1)\n",
      "f(4) = (f(2) + f(1)) + f(0)\n",
      "f(4) = (f(1) + f(0)) + f(0)\n",
      "f(4) = (F(0) + F(-1)) + F(0)\n",
      "f(4) = F(-1) + F(0)\n",
      "\n",
      "f(5) = f(4) + f(3)\n",
      "f(4) = (F(3) + F(2)) + F(1)\n",
      "f(3) = (F(2) + F(1)) + F(0)\n",
      "f(2) = (F(1) + F(0)) + F(0)\n",
      "f(2) = (F(0) + F(-1)) + F(0)\n",
      "f(2) = F(-1) + F(0)\n",
      "\n",
      "f(6) = f(5) + f(4)\n",
      "f(5) = (F(4) + F(3)) + F(2)\n",
      "f(4) = (F(3) + F(2)) + F(1)\n",
      "f(3) = (F(2) + F(1)) + F(0)\n",
      "f(2) = (F(1) + F(0)) + F(0)\n",
      "f(1) = (F(0) + F(-1)) + F(0)\n",
      "f(0) = F(-1) + F(0)\n",
      "\n",
      "따라서 f(4) = F(-1) + F(0), f(5) = F(-1) + F(0), f(6) = F(-1) + F(0)의 값을 얻습니다. 이렇게 하면 일반적으로 알려진 피보나치 수열과 같이 다른 모든 숫자를 찾을 수 있습니다. 예를 들어, f(7) = F(-1) + F(0)은 f(8) = F(-1) + F(0)이므로, 이는 0과 1을 연속적으로 반복함으로써 나타낼 수 있습니다.\n",
      "\n",
      "요약하자면, 피보나치 수열은 0과 1로 시작하는 수열이며, 각 항을 이전 항과 더하기로 사용할 수 있기 때문에 연쇄적인 계산을 통해 유사한 수열과 같은 결과를 얻을 수 있습니다. 0과 1을 연속적으로 반복하면 특정 값이 나오는 것을 볼 수 있습니다. 이러한 수열은 고전적인 수학 문제에서 중요한 역할을 합니다. 그러나 수열의 순서와 방법에 따라 다르게 나타날 수 있으며, 일반적으로 파워 팩터 또는 제곱 법칙을 사용하여 정확하게 표현해야 할 수도 있습니다. 피보나치 수열은 일반적인 수학적 개념과 관련이 없는 것으로 간주되는 경우도 있습니다. 따라서 피보나치 수열의 정의와 특성을 자세히 이해하는 것은 재미있지만 일반적인 수학적 개념이 아닙니다. 하지만 수열의 본질에 대한 이해가 높아지면 다양한 방식으로 나타나는 미묘한 차이를 이해하거나 예상치 못한 결과를 만들어내는 특수한 상황을 이해하는 데 도움이 될 수 있습니다. 또한 피보나치 수열을 사용하여 수학자들이 발견한 중요한 정리와 모순이 되는 특성이나 결과를 보여줄 수 있다는 점도 강조합니다. 따라서 피보나치 수열은 수학자에게 배우고 연구하는 것뿐만 아니라 수학적 관점에서 다양한 수열의 특성을 이해하는 것과 직접적으로 관련이 있을 뿐만 아니라 일반적인 수학적 개념에도 적용될 수 있는 놀라운 개념입니다. 따라서 피보나치 수열에 대한 자세한 설명과 특성을 제공하는 글을 쓰기로 결정했습니다. 감사합니다!<|end_of_text|>\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "다음 지시사항에 대한 응답을 작성해 주세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "피보나치 수열에 대해 설명해주세요.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "피보나치 수열은 유일한 두 숫자, 0과 1로 시작하는 수열입니다. 이 수열은 다음의 방정식을 사용하여 정렬된 방식으로 계속 확장됩니다:\n",
      "\n",
      "f(n) = f(n-1) + f(n-2)\n",
      "\n",
      "이제 f(4), f(5), f(6)을 구해 봅시다. 첫 번째 피보나치 수열인 0과 1을 계산하고 그 다음 두 항을 계산합니다.\n",
      "\n",
      "f(4) = f(3) + f(2)\n",
      "f(3) = f(2) + f(1)\n",
      "f(2) = f(1) + f(0)\n",
      "\n",
      "따라서 f(4)는 다음과 같습니다:\n",
      "f(4) = (f(3) + f(2)) + f(1)\n",
      "f(4) = (f(2) + f(1)) + f(0)\n",
      "f(4) = (f(1) + f(0)) + f(0)\n",
      "f(4) = (F(0) + F(-1)) + F(0)\n",
      "f(4) = F(-1) + F(0)\n",
      "\n",
      "f(5) = f(4) + f(3)\n",
      "f(4) = (F(3) + F(2)) + F(1)\n",
      "f(3) = (F(2) + F(1)) + F(0)\n",
      "f(2) = (F(1) + F(0)) + F(0)\n",
      "f(2) = (F(0) + F(-1)) + F(0)\n",
      "f(2) = F(-1) + F(0)\n",
      "\n",
      "f(6) = f(5) + f(4)\n",
      "f(5) = (F(4) + F(3)) + F(2)\n",
      "f(4) = (F(3) + F(2)) + F(1)\n",
      "f(3) = (F(2) + F(1)) + F(0)\n",
      "f(2) = (F(1) + F(0)) + F(0)\n",
      "f(1) = (F(0) + F(-1)) + F(0)\n",
      "f(0) = F(-1) + F(0)\n",
      "\n",
      "따라서 f(4) = F(-1) + F(0), f(5) = F(-1) + F(0), f(6) = F(-1) + F(0)의 값을 얻습니다. 이렇게 하면 일반적으로 알려진 피보나치 수열과 같이 다른 모든 숫자를 찾을 수 있습니다. 예를 들어, f(7) = F(-1) + F(0)은 f(8) = F(-1) + F(0)이므로, 이는 0과 1을 연속적으로 반복함으로써 나타낼 수 있습니다.\n",
      "\n",
      "요약하자면, 피보나치 수열은 0과 1로 시작하는 수열이며, 각 항을 이전 항과 더하기로 사용할 수 있기 때문에 연쇄적인 계산을 통해 유사한 수열과 같은 결과를 얻을 수 있습니다. 0과 1을 연속적으로 반복하면 특정 값이 나오는 것을 볼 수 있습니다. 이러한 수열은 고전적인 수학 문제에서 중요한 역할을 합니다. 그러나 수열의 순서와 방법에 따라 다르게 나타날 수 있으며, 일반적으로 파워 팩터 또는 제곱 법칙을 사용하여 정확하게 표현해야 할 수도 있습니다. 피보나치 수열은 일반적인 수학적 개념과 관련이 없는 것으로 간주되는 경우도 있습니다. 따라서 피보나치 수열의 정의와 특성을 자세히 이해하는 것은 재미있지만 일반적인 수학적 개념이 아닙니다. 하지만 수열의 본질에 대한 이해가 높아지면 다양한 방식으로 나타나는 미묘한 차이를 이해하거나 예상치 못한 결과를 만들어내는 특수한 상황을 이해하는 데 도움이 될 수 있습니다. 또한 피보나치 수열을 사용하여 수학자들이 발견한 중요한 정리와 모순이 되는 특성이나 결과를 보여줄 수 있다는 점도 강조합니다. 따라서 피보나치 수열은 수학자에게 배우고 연구하는 것뿐만 아니라 수학적 관점에서 다양한 수열의 특성을 이해하는 것과 직접적으로 관련이 있을 뿐만 아니라 일반적인 수학적 개념에도 적용될 수 있는 놀라운 개념입니다. 따라서 피보나치 수열에 대한 자세한 설명과 특성을 제공하는 글을 쓰기로 결정했습니다. 감사합니다!<|end_of_text|>\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
